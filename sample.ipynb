{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello, world\n"
     ]
    }
   ],
   "source": [
    "print(\"hello, world\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import zipfile\n",
    "os.getcwd()\n",
    "os.listdir('data')\n",
    "\n",
    "\n",
    "data_dir = Path(\"/projectnb/ds340/projects/Fall_2025_Shaik_Wrenn_Hear_Me_Out/data\")\n",
    "for zip_path in data_dir.glob(\"*.zip\"):\n",
    "    extract_to = data_dir / zip_path.stem\n",
    "    extract_to.mkdir(exist_ok=True)\n",
    "    with zipfile.ZipFile(zip_path, \"r\") as z:\n",
    "        z.extractall(extract_to)\n",
    "\n",
    "from pathlib import Path\n",
    "import librosa\n",
    "\n",
    "data_dir = Path(\"/projectnb/ds340/projects/Fall_2025_Shaik_Wrenn_Hear_Me_Out/data\")\n",
    "wav_files = list(data_dir.rglob(\"*.wav\"))\n",
    "\n",
    "print(f\"Found {len(wav_files)} audio files\")\n",
    "if wav_files:\n",
    "    sample_file = wav_files[0]\n",
    "    y, sr = librosa.load(sample_file, sr=None)\n",
    "    print(f\"Loaded: {sample_file.name}\")\n",
    "    print(f\"Sampling rate: {sr} Hz\")\n",
    "else:\n",
    "    print(\"No audio files found â€” check your path or extraction.\")\n",
    "\n",
    "    #referenced chatgpt \n",
    "\n",
    "import seaborn as sns \n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "\n",
    "sns.set(style=\"whitegrid\", context=\"talk\", palette=\"deep\")\n",
    "data_dir = Path(\"/projectnb/ds340/projects/Fall_2025_Shaik_Wrenn_Hear_Me_Out/data\")\n",
    "wav_files = list(data_dir.rglob(\"*.wav\"))\n",
    "print(f\"Found {len(wav_files)} audio files total\")\n",
    "\n",
    "def parse_ravdess_filename(file_path):\n",
    "    parts = file_path.stem.split(\"-\")\n",
    "    return {\n",
    "        \"path\": str(file_path),\n",
    "        \"modality\": parts[0],\n",
    "        \"vocal_channel\": parts[1],\n",
    "        \"emotion\": parts[2],\n",
    "        \"intensity\": parts[3],\n",
    "        \"statement\": parts[4],\n",
    "        \"repetition\": parts[5],\n",
    "        \"actor\": parts[6],\n",
    "    }\n",
    "\n",
    "metadata = [parse_ravdess_filename(p) for p in wav_files]\n",
    "df = pd.DataFrame(metadata)\n",
    "print(df.head())\n",
    "\n",
    "\n",
    "emotion_labels = {\n",
    "    \"01\": \"neutral\",\n",
    "    \"02\": \"calm\",\n",
    "    \"03\": \"happy\",\n",
    "    \"04\": \"sad\",\n",
    "    \"05\": \"angry\",\n",
    "    \"06\": \"fearful\",\n",
    "    \"07\": \"disgust\",\n",
    "    \"08\": \"surprised\"\n",
    "}\n",
    "df[\"emotion_label\"] = df[\"emotion\"].map(emotion_labels)\n",
    "\n",
    "#based on code here: https://zenodo.org/records/1188976\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"no. of unique actors:\", df[\"actor\"].nunique())\n",
    "print(\"no. emotions:\", df[\"emotion_label\"].unique())\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "sns.countplot(y=\"emotion_label\", data=df, order=df[\"emotion_label\"].value_counts().index)\n",
    "plt.title(\"files/emotion\")\n",
    "plt.xlabel(\"count\")\n",
    "plt.ylabel(\"emotion :)\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "durations = []\n",
    "for speed in wav_files[:1000]: #arb number \n",
    "    y, sr = librosa.load(speed, sr=None)\n",
    "    durations.append(len(y) / sr)\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "sns.histplot(durations, bins=30, kde=True)\n",
    "plt.xlabel(\"durations (secs)\")\n",
    "plt.title(\"dist of durations\")\n",
    "plt.show()\n",
    "\n",
    "import random\n",
    "nums = [random.randint(1, 500) for x in range(5)]\n",
    "#print(nums)\n",
    "\n",
    "for i in nums:\n",
    "    sample = wav_files[i]\n",
    "    y, sr = librosa.load(sample, sr=None)\n",
    "\n",
    "    plt.figure(figsize=(14,5))\n",
    "    librosa.display.waveshow(y, sr=sr)\n",
    "    plt.title(f\"Waveform: {Path(sample).name}\")\n",
    "    plt.show()\n",
    "\n",
    "    # Spectrogram\n",
    "    plt.figure(figsize=(10,6))\n",
    "    spec = librosa.amplitude_to_db(np.abs(librosa.stft(y)), ref=np.max)\n",
    "    librosa.display.specshow(spec, sr=sr, x_axis='time', y_axis='hz', cmap='magma')\n",
    "    plt.title(\"Spectrogram (dB)\")\n",
    "    plt.colorbar(format=\"%+2.0f dB\")\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
